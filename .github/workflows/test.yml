name: Test Suite

on:
  push:
    branches: [ main, develop, 'feature/*' ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: true
        default: 'all'
        type: choice
        options:
          - unit
          - integration
          - benchmark
          - all
      environment:
        description: 'Environment to test against'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production

env:
  PYTHON_VERSION: '3.9'
  AWS_REGION: 'us-east-1'

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'unit' || github.event.inputs.test_type == 'all' || github.event.inputs.test_type == ''
    
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-xdist pytest-mock
          pip install -r src/publisher/requirements.txt
          pip install -r src/subscriber/requirements.txt
          pip install moto boto3 requests
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --cov-report=term-missing -n auto
      
      - name: Upload coverage results
        uses: actions/upload-artifact@v3
        with:
          name: coverage-${{ matrix.python-version }}
          path: |
            coverage.xml
            htmlcov/

  code-quality:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install quality tools
        run: |
          python -m pip install --upgrade pip
          pip install black isort flake8 mypy bandit safety pre-commit
      
      - name: Run black formatter check
        run: black --check --diff src/
      
      - name: Run isort import sorter check
        run: isort --check-only --diff src/
      
      - name: Run flake8 linter
        run: flake8 src/ --max-line-length=100 --ignore=E203,W503 --statistics
      
      - name: Run mypy type checker
        run: mypy src/ --ignore-missing-imports --strict-optional
      
      - name: Run bandit security check
        run: bandit -r src/ -f json -o bandit-report.json
        continue-on-error: true
      
      - name: Run safety dependency check
        run: safety check --json --output safety-report.json
        continue-on-error: true
      
      - name: Upload security reports
        uses: actions/upload-artifact@v3
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  integration-tests:
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'integration' || github.event.inputs.test_type == 'all' || (github.event_name == 'schedule')
    
    env:
      TEST_ENVIRONMENT: ${{ github.event.inputs.environment || 'dev' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest boto3 requests
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: '1.6.0'
          terraform_wrapper: false
      
      - name: Get deployment outputs
        id: outputs
        run: |
          cd terraform
          terraform init
          terraform workspace select ${{ env.TEST_ENVIRONMENT }} || (echo "Environment ${{ env.TEST_ENVIRONMENT }} not found" && exit 1)
          
          echo "sns_topic_arn=$(terraform output -raw sns_topic_arn)" >> $GITHUB_OUTPUT
          echo "publisher_function_name=$(terraform output -raw publisher_lambda_function_name)" >> $GITHUB_OUTPUT
          echo "subscriber_function_name=$(terraform output -raw subscriber_lambda_function_name)" >> $GITHUB_OUTPUT
          echo "dlq_url=$(terraform output -raw dlq_url)" >> $GITHUB_OUTPUT
          
          if terraform output api_gateway_url > /dev/null 2>&1; then
            echo "api_gateway_url=$(terraform output -raw api_gateway_url)" >> $GITHUB_OUTPUT
          fi
      
      - name: Run integration tests
        env:
          TEST_SNS_TOPIC_ARN: ${{ steps.outputs.outputs.sns_topic_arn }}
          TEST_PUBLISHER_FUNCTION_NAME: ${{ steps.outputs.outputs.publisher_function_name }}
          TEST_SUBSCRIBER_FUNCTION_NAME: ${{ steps.outputs.outputs.subscriber_function_name }}
          TEST_DLQ_URL: ${{ steps.outputs.outputs.dlq_url }}
          TEST_API_GATEWAY_URL: ${{ steps.outputs.outputs.api_gateway_url }}
          TEST_AWS_REGION: ${{ env.AWS_REGION }}
        run: |
          pytest tests/integration/ -v --tb=short
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: test-results/

  benchmark-tests:
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'benchmark' || github.event.inputs.test_type == 'all' || (github.event_name == 'schedule')
    
    env:
      TEST_ENVIRONMENT: ${{ github.event.inputs.environment || 'dev' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install benchmark dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest boto3 requests numpy matplotlib pandas
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: '1.6.0'
          terraform_wrapper: false
      
      - name: Get deployment outputs
        id: outputs
        run: |
          cd terraform
          terraform init
          terraform workspace select ${{ env.TEST_ENVIRONMENT }} || (echo "Environment ${{ env.TEST_ENVIRONMENT }} not found" && exit 1)
          
          echo "sns_topic_arn=$(terraform output -raw sns_topic_arn)" >> $GITHUB_OUTPUT
          echo "publisher_function_name=$(terraform output -raw publisher_lambda_function_name)" >> $GITHUB_OUTPUT
          echo "subscriber_function_name=$(terraform output -raw subscriber_lambda_function_name)" >> $GITHUB_OUTPUT
      
      - name: Run benchmark tests
        env:
          TEST_SNS_TOPIC_ARN: ${{ steps.outputs.outputs.sns_topic_arn }}
          TEST_PUBLISHER_FUNCTION_NAME: ${{ steps.outputs.outputs.publisher_function_name }}
          TEST_SUBSCRIBER_FUNCTION_NAME: ${{ steps.outputs.outputs.subscriber_function_name }}
          TEST_AWS_REGION: ${{ env.AWS_REGION }}
        run: |
          python tests/benchmarks/benchmark.py
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: benchmark-results/

  test-report:
    runs-on: ubuntu-latest
    needs: [unit-tests, code-quality, integration-tests, benchmark-tests]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v3
      
      - name: Generate test report
        run: |
          mkdir -p test-report
          
          echo "# Test Suite Report" > test-report/README.md
          echo "Generated: $(date)" >> test-report/README.md
          echo "" >> test-report/README.md
          
          echo "## Test Results" >> test-report/README.md
          echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> test-report/README.md
          echo "- Code Quality: ${{ needs.code-quality.result }}" >> test-report/README.md
          echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> test-report/README.md
          echo "- Benchmark Tests: ${{ needs.benchmark-tests.result }}" >> test-report/README.md
          echo "" >> test-report/README.md
          
          echo "## Coverage Reports" >> test-report/README.md
          if [ -d "coverage-3.9" ]; then
            echo "Coverage reports available for Python 3.9" >> test-report/README.md
          fi
          
          echo "## Security Scan Results" >> test-report/README.md
          if [ -f "security-reports/bandit-report.json" ]; then
            echo "Bandit security scan completed" >> test-report/README.md
          fi
          if [ -f "security-reports/safety-report.json" ]; then
            echo "Safety dependency check completed" >> test-report/README.md
          fi
      
      - name: Upload test report
        uses: actions/upload-artifact@v3
        with:
          name: test-report
          path: test-report/